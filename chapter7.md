# Chapter 7：中文自然语言生成：从三元组到口语化表达

## 1. 开篇段落

欢迎来到数据合成中最具艺术性的一步。在前面的章节中，我们通过 SPARQL 获得了大量精确但冰冷的结构化数据（JSON/CSV）。例如 `{"entity": "李白", "property": "P569", "value": "+0701-02-28T00:00:00Z"}`。

如果你直接把这些数据喂给对话模型训练，模型学会的将是“机器语”。本章的目标是**跨越“结构化事实”到“自然中文对话”的鸿沟**。这不仅仅是简单的填空游戏，它涉及：
1.  **数据清洗（Normalization）**：把数据库格式（ISO时间、QID单位）变成人类可读格式。
2.  **句法构建（Realization）**：如何根据属性类型选择正确的疑问词（谁/哪/什么/几）和量词。
3.  **多轮连贯性（Coherence）**：在对话中正确使用代词（他/她/它）和省略主语，避免重复啰嗦。
4.  **风格化（Stylization）**：如何让机器人既能像百科全书一样严谨，又能像朋友一样闲聊。

---

## 2. 核心论述

### 2.1 数据到文本的完整流水线 (The Pipeline)

一个成熟的对话生成系统通常包含以下模块：

```ascii
[ Wikidata Raw Response ]
       | (JSON)
       v
+-----------------------------+
| 1. 规范化器 (Normalizer)    | <-- "脏活累活"：日期清洗、单位换算、名称回退
+-----------------------------+
       | (Cleaned Dict)
       v
+-----------------------------+
| 2. 语义映射 (Semantic Map)  | <-- 决定用什么词：P569 -> "生日"/"诞辰"
+-----------------------------+
       | (Schema)
       v
+-----------------------------+
| 3. 生成策略 (Strategy)      | <-- 决定怎么说：模板填槽 OR LLM重写
+-----------------------------+
       | (Sentences)
       v
+-----------------------------+
| 4. 上下文注入 (Contextual)  | <-- 多轮处理：指代消解、连接词插入
+-----------------------------+
       |
       v
[ Final Dialogue Dataset ]
```

### 2.2 规范化：处理 Wikidata 的“生肉”

Wikidata 的原始数据在直接使用前必须经过严格的清洗。以下是三个最关键的领域：

#### A. 时间的深度处理 (Temporal Normalization)
Wikidata 使用 ISO 8601 扩展格式，关键在于处理 **Precision (精度)** 字段。

| Precision 代码 | 含义 | 原始值示例 | 目标中文表达 | 逻辑处理提示 |
| :--- | :--- | :--- | :--- | :--- |
| **11** | 日 | `+1998-05-12T...` | 1998年5月12日 | 最常见，标准格式 |
| **10** | 月 | `+1998-05-00T...` | 1998年5月 | 去掉 T 后面的部分，忽略日 |
| **9** | 年 | `+1998-00-00T...` | 1998年 | 仅提取前四位 |
| **8** | 十年 | `+1990-00-00T...` | 20世纪90年代 | `(Year // 10) * 10` + "年代" |
| **7** | 世纪 | `+1900-00-00T...` | 20世纪 | `(Year // 100) + 1` + "世纪" |

*   **陷阱：公元前**。若原始值以 `-` 开头（如 `-0221`），需转换为“公元前221年”。
*   **口语化技巧**：对于最近 5 年内的时间，可以转换为相对时间：“去年”、“前年”。

#### B. 量纲与单位的本地化 (Units & Measures)
属性 `P2048` (身高) 可能返回 `1.78`，单位是 `Q11573` (米)。
属性 `P2067` (质量) 可能返回 `170`，单位是 `Q11570` (磅)。

1.  **建立映射表**：维护一个 `unit_map.json`。
    ```json
    {
      "Q11573": {"label": "米", "format": "{value}米"},
      "Q11570": {"label": "千克", "convert_from_lbs": 0.453592}, 
      "Q4917":  {"label": "美元", "prefix": "$", "suffix": "美元"}
    }
    ```
2.  **数值修剪**：Wikidata 常包含极高精度的浮点数（如 `1.78999999`）。务必进行 `round(x, 1)` 或 `round(x, 0)` 处理。
3.  **大数缩略**：中文习惯用“万”、“亿”。`15,000,000` 应转化为 `1500万`，而不是 `一千五百万` 或 `1.5E7`。

#### C. 实体名称的回退策略 (Label Fallback)
这是中文数据构建最大的痛点：**很多实体没有中文 Label**。
建议的优先级逻辑：
1.  `zh-cn` label (简体中文)
2.  `zh` / `zh-hans` / `zh-hant` (繁体需转简体)
3.  **Alias (别名)**：有时 Label 缺失但 Alias 里有中文。
4.  **Fallback (英文)**：保留英文原名。
5.  **LLM 辅助翻译 (可选)**：如果上述都失败，且该实体很重要，调用 LLM 翻译并缓存。

### 2.3 模板工程：从“填空”到“造句”

不要只写一个模板！为了保证数据的多样性，我们需要构建一个**模板库**。

#### A. 属性感知的模板设计
不同类型的属性需要不同的问法（Wh-words）：

*   **P569 (时间类)** -> 什么时候 / 哪一年 / 多大
    *   T1: `{S}是哪一年出生的？`
    *   T2: `告诉我{S}的生日。`
*   **P19 (地点类)** -> 哪里 / 哪座城市
    *   T1: `{S}的老家是哪？`
    *   T2: `{S}出生在什么地方？`
*   **P161 (人物列表类)** -> 谁 / 哪些人
    *   T1: `谁演了{S}？`
    *   T2: `{S}的主演名单里都有谁？`

#### B. 增加“人味”的修饰语
在模板中随机插入**语篇标记（Discourse Markers）**，模拟真实对话：
*   **前缀**：`嗯...`, `我想想，`, `据我所知，`, `资料显示，`
*   **后缀**：`吧。`, `哦。`, `呢。`
*   **示例**：
    *   机器味：`李白出生于701年。`
    *   人味：`据记载，李白是701年出生的。` / `他大概是在701年出生的吧。`

### 2.4 进阶：利用 LLM 进行 Paraphrasing (复述)

为了突破模板的僵硬，我们可以使用 LLM 对构建好的“半成品”进行润色。

**Pipeline 变体：**
1.  **构造 Prompt**：包含结构化事实 + 目标风格。
2.  **输入**：`Fact: [埃隆·马斯克, CEO, SpaceX]; Style: 幽默闲聊`
3.  **LLM 输出**：`虽然马斯克管的事儿很多，但他最著名的头衔还得是 SpaceX 的老大。`

**Cost-Saving Trick (省钱技巧)**：
不要对每条数据都调 LLM。
1.  用 LLM 生成 50 个高质量模板。
2.  人工校验这 50 个模板。
3.  用 Python 代码随机填充这 50 个模板。
(这种方法叫 "LLM-assisted Template Engineering")。

### 2.5 多轮对话的结构化

多轮对话的核心在于**信息的逐渐披露**和**指代的连贯性**。

#### 场景：追问 (Follow-up)
*   **Turn 1**: 询问核心事实。
    *   User: 谁导演了《流浪地球》？
    *   Bot: 是**郭帆**导演的。
*   **Turn 2**: 基于 Turn 1 的 Object (郭帆) 进行追问。
    *   *(后台查询郭帆 (Q...) 的其他属性，如出生地)*
    *   User: 那**他**是哪里人？ (这里用“他”替换了“郭帆”)
    *   Bot: **他**出生在山东济宁。

#### 规则：代词选择逻辑
构建一个函数 `get_pronoun(entity_id)`：
1.  检查 `P21` (性别)。
    *   `Q6581097` (男) -> **他**
    *   `Q6581072` (女) -> **她**
2.  若无性别，检查 `P31` (类型)。
    *   若属于 `组织 (Q43229)` -> **这家** / **该机构**
    *   若属于 `作品` -> **这部** / **它**
3.  **零指代 (Zero Anaphora)**：中文允许完全省略主语。
    *   Bot: “出生在山东济宁。” (完全自然)

---

## 3. 本章小结

*   **数据清洗是地基**：时间精度、单位换算、中英混合处理直接决定数据质量。
*   **模板需要分层**：针对不同属性类型（时间/地点/人物/数值）设计特定的疑问词和句式。
*   **多轮靠指代**：利用 P21（性别）和 P31（类型）自动推断“他/她/它”，或者大胆使用中文的“零指代”特性。
*   **多样性策略**：通过 LLM 辅助扩充模板库，或对生成的文本进行风格迁移（Style Transfer），避免千篇一律的百科腔。

---

## 4. 练习题

### 基础题

**练习 7.1：单位与数值处理**
你需要处理属性 `P2048` (身高)。
Wikidata 返回：`amount: "+1.853"`, `unit: "http://www.wikidata.org/entity/Q11573"` (米)。
请写出转化为以下两种风格的逻辑和结果：
1.  **精准百科风**
2.  **口语闲聊风**

<details>
<summary>点击查看答案</summary>

**答案：**
1.  **精准百科风**：
    *   逻辑：保留两位小数，拼接单位“米”。
    *   结果：“1.85米”
2.  **口语闲聊风**：
    *   逻辑：将 1.x 米转换为“一米x”。如果是 1.853，可以四舍五入到 1.85，说“一米八五”。
    *   结果：“大概一米八五吧” 或 “一米八五左右”。
</details>

**练习 7.2：列表截断逻辑**
查询某歌手的 `P136` (曲风/Genre) 返回了 8 个结果：[Pop, R&B, Soul, Hip-hop, Dance, Electronic, Funk, Disco]。
请设计一个生成策略，避免回答过长，同时保证信息准确。

<details>
<summary>点击查看答案</summary>

**答案：**
**策略：Top-N + "等"**
1.  **排序**：如果没有固有顺序，随机取 2-3 个（增加数据多样性），或者取最短的中文词。
2.  **模板**：`"{S}的曲风主要是{O1}、{O2}这些。"` 或 `"{S}涉猎广泛，包括{O1}、{O2}等风格。"`
3.  **生成**：“他的曲风主要是流行、R&B和灵魂乐这些。”
</details>

**练习 7.3：代词推断**
实体：`Q230` (斯蒂芬·斯皮尔伯格)。属性 `P21` 为 `Q6581097` (Male)。
实体：`Q142` (法兰西共和国)。属性 `P21` 缺失，`P31` 为 `Q3624078` (Sovereign State)。
请分别为这两个实体在第二轮对话中选择合适的代词。

<details>
<summary>点击查看答案</summary>

**答案：**
*   **斯皮尔伯格**：检测到 P21=Male -> 使用 **“他”** 或 **“这位导演”**。
*   **法国**：检测到 P21 缺失，P31 是国家/政体 -> 使用 **“这个国家”** 或 **“它”**。
</details>

---

### 挑战题

**练习 7.4：处理“限定符” (Qualifiers) 的复杂句生成**
**事实**：[李娜 (Q298220), 获胜 (P2522), 法国网球公开赛 (Q102376)]
**限定符**：[时间点 (P585): 2011年]
请利用上述信息，生成一个包含**追问**的 **User-Bot-User-Bot** 两轮对话。

<details>
<summary>点击查看答案</summary>

**答案示例：**
*   **Turn 1**
    *   User: 李娜拿过法网冠军吗？ (基于主事实 P2522 生成问句)
    *   Bot: 拿过，她是法网冠军。
*   **Turn 2** (利用 Qualifier P585 构造追问)
    *   User: 那是哪一年的事？ / 什么时候拿的？
    *   Bot: 是在2011年拿的。 (提取 Qualifier 生成回答)
    
    *或者合并在一句中：*
    *   User: 李娜哪年拿的法网？
    *   Bot: 2011年。
</details>

**练习 7.5：消除歧义的自然语言生成**
你有两个实体都叫“李白”。
1.  Q7074: 诗人 (Tang Dynasty poet)
2.  Q10565882: 间谍 (Secret agent)
当用户问“李白是谁？”时，请设计一个回复模板，能够同时涵盖这两个实体，或者引导用户澄清。

<details>
<summary>点击查看答案</summary>

**答案：**
**策略：澄清式反问 (Clarification)**
*   **模板**：`你是想问{Desc1}的那个{Label}，还是{Desc2}的那个？`
*   **数据填充**：利用 Wikidata 的 `description` 字段。
*   **结果**：
    *   Bot: “你是问唐朝的那位大诗人李白，还是《永不消逝的电波》里的那个角色？”
    
**策略：默认头部 + 补充**
*   **逻辑**：Q7074 的 sitelinks 数量远大于 Q10565882，判定为头部实体。
*   **结果**：
    *   Bot: “通常是指唐朝诗人李白。不过也有一个同名的影视角色，你想了解哪个？”
</details>

**练习 7.6：开放性思考 - LLM 幻觉控制**
你决定使用 LLM 将 `{S} {P} {O}` 改写成生动的句子。但你发现，对于事实 `[特斯拉, 创始人, 马斯克]`，LLM 有时会生成“马斯克在2003年创立了特斯拉”（**错误：马斯克其实是早期投资人，严格法律意义上的创始人是 Eberhard 和 Tarpenning，虽然 Tesla 官方后来承认了马斯克的 Founder 头衔，但 2003 年创立这个动作本身有争议**）。
请设计一个 Prompt 策略或校验流程，尽量减少这种“添加额外错误细节”的幻觉。

<details>
<summary>点击查看答案</summary>

**答案：**
1.  **Prompt 约束**：在 Prompt 中明确加入 Negative Constraint。
    *   `"请仅依据提供的三元组信息进行改写，严禁添加任何时间、地点或背景描述，除非三元组中显式包含这些信息。"`
2.  **Fact Verification (事后校验)**：
    *   使用 NLI (Natural Language Inference) 模型。
    *   Premise: 结构化三元组转换成的简单句。
    *   Hypothesis: LLM 生成的句子。
    *   如果 Entailment 分数过低（即生成的句子包含了原数据没有的信息），则丢弃该生成结果，回退到模板版。
3.  **One-shot 示例**：
    *   User: [李白, 职业, 诗人] -> 李白是唐朝最伟大的诗人 (错误，原文没说唐朝/最伟大)。
    *   User: [李白, 职业, 诗人] -> 李白是一名诗人 (正确)。
    *   通过示例告诉 LLM 边界在哪里。
</details>

---

## 5. 常见陷阱与错误 (Gotchas)

### 1. 多个值的连接词灾难
*   **错误**：`李白的职业是诗人、书法家、作家、剑客。` (僵硬)
*   **错误**：`李白的职业是诗人，和书法家，和作家。` (翻译腔：A, and B, and C)
*   **修复**：检测列表长度。如果 > 2，前几个用顿号 `、`，最后一个用 `和` 或 `以及`。
    *   `李白既是诗人、书法家，也是一位剑客。`

### 2. "是" 字句的滥用 (Copula Overuse)
*   **现象**：`他的出生地是北京。他的职业是医生。他的爱好是篮球。`
*   **原因**：过度依赖 `{Subject} 的 {Property} 是 {Object}` 模板。
*   **修复**：动词化。
    *   `出生地` -> `他出生在北京。`
    *   `职业` -> `他当过医生。` / `他是做医生的。`
    *   `工作于` -> `他在...工作。`

### 3. 古今地名混淆
*   **场景**：Wikidata 中 `李白` 的出生地可能链接到 `碎叶城 (Q849683)`。
*   **生成**：`李白出生在碎叶城。` (没问题)
*   **潜在问题**：如果此时你试图把 `碎叶城` 映射到现代国家 `吉尔吉斯斯坦` 并生成 `李白是吉尔吉斯斯坦人`，这就极其违和且引发争议。
*   **Rule of Thumb**：处理历史人物时，尽量使用当时的地理名称（Wikidata 通常会区分历史行政区划实体）。不要随意通过 `P17` (国家) 推断现代国籍。

### 4. 括号与特殊字符的残留
*   **现象**：`这部电影是钢铁侠 (2008年电影)。`
*   **原因**：直接使用了 Wikidata 带消歧义后缀的 Label。
*   **修复**：Regex 清洗。`re.sub(r'（.*?）|\(.*?\)', '', text)`。一定要去掉 Label 中的括号内容。

---
[< Chapter 6: 自动化抓取与缓存](chapter6.md) | [Chapter 8: 质量控制与评估 >](chapter8.md)
