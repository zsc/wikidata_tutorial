# Chapter 6ï¼šè‡ªåŠ¨åŒ–æŠ“å–ä¸ç¼“å­˜ï¼šä» WDQS åˆ°æœ¬åœ°æ•°æ®ç®¡é“

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œä½ å·²ç»æŒæ¡äº† SPARQL æŸ¥è¯¢çš„ç¼–å†™æŠ€å·§ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬é¢ä¸´çš„é—®é¢˜æ˜¯å¦‚ä½•å°†â€œä¸€æ¬¡æ€§æŸ¥è¯¢â€è½¬å˜ä¸ºâ€œç”Ÿäº§çº§æ•°æ®æµæ°´çº¿â€ã€‚

å¦‚æœä½ åªæ˜¯æƒ³ä¸‹è½½å‡ ç™¾æ¡æ•°æ®ï¼Œç‚¹å‡» WDQS ç½‘é¡µä¸Šçš„ Download æŒ‰é’®å°±å¤Ÿäº†ã€‚ä½†å¯¹äº**æ„é€ å¯¹è¯æ•°æ®**è€Œè¨€ï¼Œæˆ‘ä»¬é€šå¸¸é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
1. **æ•°æ®é‡å¤§**ï¼šéœ€è¦é‡‡æ ·æ•°ä¸‡ç”šè‡³æ•°åä¸‡ä¸ªå®ä½“ã€‚
2. **æŸ¥è¯¢å¤æ‚**ï¼šå•ä¸€æŸ¥è¯¢å®¹æ˜“è¶…æ—¶ï¼ˆTimeoutï¼‰ã€‚
3. **ç½‘ç»œä¸ç¨³å®š**ï¼šWDQS æ˜¯å…¬å…±èµ„æºï¼Œä¼šæœ‰é€Ÿç‡é™åˆ¶ï¼ˆRate Limitï¼‰å’Œå¶å°”çš„å®•æœºã€‚
4. **è¿­ä»£é¢‘ç¹**ï¼šä½ ä¿®æ”¹äº† Prompt æ¨¡æ¿ï¼Œéœ€è¦é‡æ–°è·‘æ•°æ®ï¼Œå¦‚æœæ¯æ¬¡éƒ½é‡æ–°è¯·æ±‚ APIï¼Œæ•ˆç‡æä½ä¸”ä¸ç¯ä¿ã€‚

æœ¬ç« å°†æŒ‡å¯¼ä½ ä½¿ç”¨ Python æ„å»ºä¸€ä¸ªå¥å£®çš„ï¼ˆRobustï¼‰ã€æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œæœ¬åœ°ç¼“å­˜çš„æ•°æ®æŠ“å–ç³»ç»Ÿã€‚

---

## 1. å­¦ä¹ ç›®æ ‡

- **æŒæ¡ WDQS API åè®®**ï¼šHTTP æ–¹æ³•é€‰æ‹©ã€User-Agent è§„èŒƒã€JSON å“åº”è§£æã€‚
- **æ„å»ºå¥å£®çš„è¯·æ±‚å™¨**ï¼šå®ç°æŒ‡æ•°é€€é¿ï¼ˆExponential Backoffï¼‰é‡è¯•æœºåˆ¶ï¼Œä¼˜é›…å¤„ç† 429/50x é”™è¯¯ã€‚
- **å®æ–½é«˜æ•ˆç¼“å­˜ç­–ç•¥**ï¼šå®ç°â€œQuery Hashâ€ç¼“å­˜ï¼Œå°†ç½‘ç»œ IO è½¬åŒ–ä¸ºæœ¬åœ°ç£ç›˜ IOã€‚
- **è§£å†³å¤§è§„æ¨¡æ•°æ®è·å–**ï¼šæ”¾å¼ƒä½æ•ˆçš„ OFFSET åˆ†é¡µï¼ŒæŒæ¡åŸºäº ID æˆ–å±æ€§çš„â€œåˆ‡ç‰‡ï¼ˆSlicingï¼‰â€æŠ€å·§ã€‚
- **æ•°æ®æŒä¹…åŒ–**ï¼šä½¿ç”¨ JSONL æ ¼å¼æ„å»ºæµå¼æ•°æ®å¤„ç†ç®¡é“ã€‚

---

## 2. æ ¸å¿ƒæ¶æ„ï¼šæ•°æ®ç®¡é“ (The Pipeline)

ä¸€ä¸ªæˆç†Ÿçš„å¯¹è¯æ•°æ®è·å–ç³»ç»Ÿé€šå¸¸åŒ…å«å››ä¸ªæ¨¡å—ã€‚ä¸è¦åœ¨ä¸€ä¸ªè„šæœ¬é‡Œå†™å®Œæ‰€æœ‰é€»è¾‘ï¼Œåº”è¯¥å°½é‡è§£è€¦ã€‚

```ascii
[ é…ç½®å±‚: Topic Definitions ]
       | (ç”Ÿæˆ SPARQL)
       v
+-------------+      1. Check      +------------------+
|             | -----------------> |                  |
|  Fetcher    |      2. Return     |   Local Cache    |
| (Py Script) | <----------------- | (disk/sqlite)    |
|             |      (If Hit)      |                  |
+-------------+                    +------------------+
       |
       | 3. HTTP Request (If Miss)
       | (with Retry & Backoff)
       v
+-------------+                    +------------------+
|             | 4. JSON Response   |                  |
|   WDQS      | -----------------> |  Raw Data Dump   |
| (Internet)  | 5. Write Cache     |  (.jsonl files)  |
+-------------+                    +------------------+
                                           |
                                           | 6. Stream Read
                                           v
                                   +------------------+
                                   |                  |
                                   |   Normalizer     |
                                   | (Clean & Format) |
                                   |                  |
                                   +------------------+
```

### 2.1 å¿…é¡»éµå®ˆçš„è§„åˆ™ï¼šUser-Agent

Wikidata å¯¹åŒ¿åçˆ¬è™«éå¸¸æ•æ„Ÿã€‚å¦‚æœä½ çš„ Python è„šæœ¬ä¸å¸¦ Headerï¼Œé»˜è®¤ User-Agent é€šå¸¸æ˜¯ `python-requests/x.x.x`ï¼Œè¿™ä¼šè¢«ç›´æ¥å°ç¦ã€‚

**Rule of Thumb**ï¼š
> æ°¸è¿œåœ¨ Header ä¸­é™„å¸¦ä½ çš„é¡¹ç›®åç§°å’Œè”ç³»æ–¹å¼ï¼ˆé‚®ç®±ï¼‰ã€‚

```python
HEADERS = {
    'User-Agent': 'MyDialogueBot/1.0 (bot_admin@example.com) based on Wikidata-Toolkit',
    'Accept': 'application/sparql-results+json'
}
```

### 2.2 GET vs POST

WDQS æ”¯æŒ GET å’Œ POSTã€‚
- **GET**ï¼šå°†æŸ¥è¯¢æ‹¼æ¥åˆ° URL å‚æ•°ä¸­ã€‚é™åˆ¶ï¼šURL é•¿åº¦é€šå¸¸ä¸èƒ½è¶…è¿‡ 2KB~4KBã€‚
- **POST**ï¼šå°†æŸ¥è¯¢æ”¾åœ¨ Body ä¸­ã€‚é™åˆ¶ï¼šå‡ ä¹æ²¡æœ‰é•¿åº¦é™åˆ¶ã€‚

**æœ€ä½³å®è·µ**ï¼šä¸ºäº†é¿å…â€œURI Too Longâ€é”™è¯¯ï¼Œç»Ÿä¸€å°è£…ä¸€ä¸ªä½¿ç”¨ **POST** çš„è¯·æ±‚å‡½æ•°ã€‚

---

## 3. æ ¸å¿ƒæŠ€æœ¯è¯¦è§£

### 3.1 ç¼“å­˜ç­–ç•¥ï¼šä»¥æŸ¥è¯¢ä¸ºé”® (Query-as-Key)

åœ¨å¼€å‘è°ƒè¯•é˜¶æ®µï¼Œä½ å¯èƒ½ä¼šè¿è¡Œè„šæœ¬ 50 æ¬¡ã€‚å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œä½ ä¼šå¯¹ Wikidata å‘èµ· 50 æ¬¡ç›¸åŒçš„è¯·æ±‚ï¼Œæ—¢æ…¢åˆå¯èƒ½è¢«å° IPã€‚

æˆ‘ä»¬æ¨è**æ–‡ä»¶å“ˆå¸Œç¼“å­˜**ï¼š

1. è¾“å…¥ SPARQL æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚
2. è®¡ç®— MD5 å“ˆå¸Œå€¼ï¼ˆä¾‹å¦‚ `a1b2c3d4...`ï¼‰ã€‚
3. æ£€æŸ¥ `cache/a1b2c3d4.json` æ˜¯å¦å­˜åœ¨ã€‚
   - **Hit**: ç›´æ¥è¯»å–æ–‡ä»¶å†…å®¹ã€‚
   - **Miss**: å‘èµ· HTTP è¯·æ±‚ï¼ŒæˆåŠŸåå°†ç»“æœå†™å…¥è¯¥æ–‡ä»¶ã€‚

è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯**å¹‚ç­‰æ€§**ï¼ˆIdempotencyï¼‰ï¼šåªè¦æŸ¥è¯¢è¯­å¥æ²¡å˜ï¼Œç»“æœå°±æ˜¯ç¨³å®šçš„ã€‚

### 3.2 é”™è¯¯å¤„ç†ä¸æŒ‡æ•°é€€é¿

ç½‘ç»œé”™è¯¯ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š
1. **ç¡¬é”™è¯¯ (400 Bad Request)**ï¼šä½ çš„ SPARQL è¯­æ³•é”™äº†ã€‚é‡è¯• 100 æ¬¡ä¹Ÿæ²¡ç”¨ã€‚ç­–ç•¥ï¼š**æŠ›å‡ºå¼‚å¸¸ï¼Œäººå·¥ä¿®å¤**ã€‚
2. **è½¯é”™è¯¯ (429 Too Many Requests / 5xx Server Error)**ï¼šæœåŠ¡å™¨å¿™ã€‚ç­–ç•¥ï¼š**ç­‰å¾…åé‡è¯•**ã€‚

**æŒ‡æ•°é€€é¿ (Exponential Backoff)** ç®—æ³•ï¼š
- ç¬¬ 1 æ¬¡å¤±è´¥ï¼šç­‰å¾… 1 ç§’
- ç¬¬ 2 æ¬¡å¤±è´¥ï¼šç­‰å¾… 2 ç§’
- ç¬¬ 3 æ¬¡å¤±è´¥ï¼šç­‰å¾… 4 ç§’
- ...
- è¶…è¿‡æœ€å¤§æ¬¡æ•°ï¼šæ”¾å¼ƒå¹¶æŠ¥é”™ã€‚

### 3.3 å¤§è§„æ¨¡æ•°æ®çš„åˆ‡ç‰‡ç­–ç•¥ (Slicing)

è¿™æ˜¯æœ¬ç« æœ€é«˜çº§çš„æŠ€å·§ã€‚

#### âŒ åæ¨¡å¼ï¼šä½¿ç”¨ OFFSET åˆ†é¡µ
```sparql
# æä¸æ¨è
SELECT * WHERE { ... } LIMIT 1000 OFFSET 10000
```
éšç€ OFFSET å¢å¤§ï¼Œæ•°æ®åº“å¿…é¡»æ‰«æå¹¶ä¸¢å¼ƒå‰é¢çš„è®°å½•ï¼ŒæŸ¥è¯¢ä¼šå˜å¾—æå…¶ç¼“æ…¢ç›´è‡³è¶…æ—¶ï¼ˆTimeoutï¼‰ã€‚

#### âœ… æœ€ä½³å®è·µï¼šåŸºäº ID æˆ–å±æ€§åˆ‡ç‰‡

**æ–¹æ³• Aï¼šæŒ‰æ—¶é—´/æ•°å€¼åˆ‡ç‰‡**
é€‚ç”¨äºæœ‰æ˜ç¡®æ—¶é—´å±æ€§çš„æ•°æ®ï¼ˆå¦‚å‡ºç”Ÿæ—¥æœŸï¼‰ã€‚
- Query 1: 1900-1910
- Query 2: 1910-1920
- ...

**æ–¹æ³• Bï¼šæŒ‰ QID èŒƒå›´åˆ‡ç‰‡ (ä¸‡èƒ½æ³•)**
ç”±äºæ¯ä¸ªå®ä½“éƒ½æœ‰å”¯ä¸€çš„æ•°å€¼ IDï¼ˆQ123 ä¸­çš„ 123ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ SPARQL çš„å­—ç¬¦ä¸²å¤„ç†æˆ–æ•°å€¼è½¬æ¢æ¥åˆ†ç‰‡ã€‚

è™½ç„¶ SPARQL å¤„ç†å­—ç¬¦ä¸² ID è¾ƒæ…¢ï¼Œä½†æ›´é«˜æ•ˆçš„æ˜¯ç»“åˆ `wd:Q*` å®é™…ä¸Šæ˜¯ IRI çš„ç‰¹æ€§ï¼Œæˆ–è€…ç›´æ¥ä¾èµ–**å¤–éƒ¨é€»è¾‘ç”Ÿæˆå¤šæ¡æŸ¥è¯¢**ã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬è¦æŸ¥æ‰€æœ‰â€œäººç±»â€ï¼š
- ä¸è¦åœ¨ SPARQL é‡Œå†™ `LIMIT 1000000`.
- è€Œæ˜¯å†™ 10 ä¸ªæŸ¥è¯¢ï¼Œæ¯ä¸ªæŸ¥è¯¢å¢åŠ çº¦æŸï¼š
  - `Query 1`: ... ä¸” `?item` ä½äºâ€œäºšæ´²â€
  - `Query 2`: ... ä¸” `?item` ä½äºâ€œæ¬§æ´²â€
  - ...

---

## 4. å®æˆ˜ä»£ç æ„å»º

æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªåä¸º `WikidataFetcher` çš„ç±»ã€‚

### 4.1 åŸºç¡€ç»“æ„ä¸ç¼“å­˜

```python
import os
import hashlib
import json
import time
import requests

class WikidataFetcher:
    def __init__(self, cache_dir="cache"):
        self.endpoint = "https://query.wikidata.org/sparql"
        self.headers = {
            'User-Agent': 'DialogueSynthBot/0.1 (me@mysite.com)',
        }
        self.cache_dir = cache_dir
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)

    def _get_cache_path(self, query):
        # è®¡ç®— MD5
        query_hash = hashlib.md5(query.encode('utf-8')).hexdigest()
        return os.path.join(self.cache_dir, f"{query_hash}.json")
    
    def fetch(self, query, force_refresh=False):
        cache_path = self._get_cache_path(query)
        
        # 1. å°è¯•è¯»å–ç¼“å­˜
        if not force_refresh and os.path.exists(cache_path):
            print(f"Loading from cache: {cache_path}")
            with open(cache_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œå‘èµ·è¯·æ±‚
        print("Fetching from WDQS...")
        data = self._make_request(query)
        
        # 3. å†™å…¥ç¼“å­˜
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False)
            
        return data

    def _make_request(self, query):
        # å°†åœ¨ä¸‹ä¸€èŠ‚å®ç°å…·ä½“çš„è¯·æ±‚é€»è¾‘
        pass
```

### 4.2 å®ç°é‡è¯•é€»è¾‘

```python
    def _make_request(self, query):
        max_retries = 5
        for attempt in range(max_retries):
            try:
                # ä½¿ç”¨ POST æ–¹æ³•
                response = requests.post(
                    self.endpoint, 
                    data={'query': query, 'format': 'json'}, 
                    headers=self.headers,
                    timeout=60 # è®¾ç½®è¶…æ—¶å¾ˆé‡è¦
                )
                
                # 400 é”™è¯¯ç›´æ¥æŠ›å‡ºï¼Œä¸é‡è¯•
                if response.status_code == 400:
                    raise ValueError(f"SPARQL Syntax Error: {response.text}")

                # 429 æˆ– 5xx é”™è¯¯è¿›è¡Œé‡è¯•
                if response.status_code in [429, 500, 502, 503, 504]:
                    sleep_time = 2 ** attempt # 1, 2, 4, 8...
                    print(f"Error {response.status_code}. Retrying in {sleep_time}s...")
                    time.sleep(sleep_time)
                    continue
                
                response.raise_for_status() # å…¶ä»–é”™è¯¯æŠ›å‡ºå¼‚å¸¸
                
                return response.json()
                
            except requests.exceptions.RequestException as e:
                print(f"Network error: {e}")
                if attempt == max_retries - 1:
                    raise
                time.sleep(2 ** attempt)
        
        raise Exception("Max retries exceeded")
```

---

## 5. æœ¬ç« å°ç»“

1.  **å·¥ç¨‹åŒ–ç¬¬ä¸€**ï¼šä¸è¦ä¾èµ–æµè§ˆå™¨ï¼Œè¦ä¾èµ–ä»£ç ã€‚
2.  **ç¼“å­˜æ˜¯å¿…é€‰é¡¹**ï¼š`md5(query)` æ˜¯å®ç°ç¼“å­˜æœ€ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼Œèƒ½èŠ‚çœ 90% çš„è°ƒè¯•æ—¶é—´ã€‚
3.  **æ‹¥æŠ± JSONL**ï¼šåœ¨å¤„ç†åˆ—è¡¨å‹æ•°æ®æ—¶ï¼ŒJSONLï¼ˆæ¯è¡Œä¸€ä¸ª JSONï¼‰æ¯” JSON Array æ›´èŠ‚çœå†…å­˜ï¼Œæ¯” CSV è¡¨è¾¾èƒ½åŠ›æ›´å¼ºã€‚
4.  **åˆ‡ç‰‡ä¼˜äºåˆ†é¡µ**ï¼šç”¨ä¸šåŠ¡é€»è¾‘ï¼ˆæ—¶é—´ã€åœ°ç‚¹ã€IDæ®µï¼‰æ‹†åˆ†æŸ¥è¯¢ï¼Œé¿å…ä½¿ç”¨æ·±åº¦çš„ OFFSETã€‚
5.  **ç¤¼è²Œçˆ¬å–**ï¼šè®¾ç½® User-Agentï¼Œé‡åˆ° 429 è¯·ç­‰å¾…ã€‚

---

## 6. ç»ƒä¹ é¢˜

### åŸºç¡€é¢˜

**ç»ƒä¹  6.1ï¼šJSON ç»“æœæå–**
Wikidata è¿”å›çš„ JSON ç»“æ„æ¯”è¾ƒæ·±ã€‚ç¼–å†™ä¸€ä¸ªè¾…åŠ©å‡½æ•° `simplify_results(data)`ï¼Œå°†åŸå§‹çš„ SPARQL JSON å“åº”è½¬åŒ–ä¸ºç®€å•çš„å­—å…¸åˆ—è¡¨ã€‚
è¾“å…¥ç¤ºä¾‹ï¼š
```json
{"head": {...}, "results": {"bindings": [{"item": {"type": "uri", "value": "http://.../Q1"}, "itemLabel": {"value": "Cat"}}]}}
```
æœŸæœ›è¾“å‡ºï¼š
```python
[{"item": "Q1", "itemLabel": "Cat"}]
```
*æç¤ºï¼šéœ€è¦å¤„ç† value ä¸­çš„ URLï¼Œæå–æœ€åçš„ QIDã€‚*

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆæ€è·¯</summary>

```python
def simplify_results(raw_data):
    simplified = []
    bindings = raw_data.get('results', {}).get('bindings', [])
    for row in bindings:
        new_row = {}
        for key, value_obj in row.items():
            val = value_obj['value']
            # å¦‚æœæ˜¯wikidataå®ä½“URLï¼Œæå–QID
            if 'entity/Q' in val:
                val = val.split('/')[-1]
            new_row[key] = val
        simplified.append(new_row)
    return simplified
```
</details>

**ç»ƒä¹  6.2ï¼šJSONL å†™å…¥å™¨**
ç¼–å†™ä¸€ä¸ªå‡½æ•° `save_to_jsonl(data_list, filename)`ã€‚
è¦æ±‚ï¼š
1. å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºå¹¶å†™å…¥ã€‚
2. å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œ**è¿½åŠ **å†™å…¥ã€‚
3. ç¡®ä¿ä¸­æ–‡ä¸è¢«è½¬ä¹‰ï¼ˆæ˜¾ç¤ºä¸ºæ±‰å­—è€Œä¸æ˜¯ `\uXXXX`ï¼‰ã€‚

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆæ€è·¯</summary>

```python
def save_to_jsonl(data_list, filename):
    # ä½¿ç”¨ 'a' æ¨¡å¼è¿›è¡Œè¿½åŠ 
    with open(filename, 'a', encoding='utf-8') as f:
        for item in data_list:
            # ensure_ascii=False ä¿è¯ä¸­æ–‡æ­£å¸¸æ˜¾ç¤º
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
```
</details>

---

### æŒ‘æˆ˜é¢˜

**ç»ƒä¹  6.3ï¼šè‡ªåŠ¨åˆ‡åˆ†æŸ¥è¯¢ç”Ÿæˆå™¨ (Challenge)**
å‡è®¾ä½ éœ€è¦æŸ¥è¯¢ 1900 å¹´åˆ° 2020 å¹´æ¯ä¸€éƒ¨ç”µå½±çš„åç§°ã€‚å•ä¸€æŸ¥è¯¢ä¼šè¶…æ—¶ã€‚
ç¼–å†™ä¸€ä¸ª Python ç”Ÿæˆå™¨ `query_generator()`ã€‚
å®ƒæ¥å—ä¸€ä¸ªåŸºæœ¬çš„ SPARQL æ¨¡æ¿ï¼ˆåŒ…å« `{start}` å’Œ `{end}` å ä½ç¬¦ï¼‰ï¼Œèµ·å§‹å¹´ä»½å’Œç»“æŸå¹´ä»½ï¼Œä»¥åŠæ­¥é•¿ï¼ˆæ¯”å¦‚ 5 å¹´ï¼‰ã€‚
å®ƒé€šè¿‡ `yield` è¿”å›å¡«å……å¥½æ—¶é—´çš„ SPARQL å­—ç¬¦ä¸²ã€‚

*SPARQL æ—¶é—´è¿‡æ»¤æç¤º*ï¼š`FILTER(?date >= "{start}-01-01"^^xsd:dateTime && ?date < "{end}-01-01"^^xsd:dateTime)`

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆæ€è·¯</summary>

```python
def query_generator(base_template, start_year, end_year, step=5):
    current = start_year
    while current < end_year:
        next_val = min(current + step, end_year)
        # æ„é€ å‚æ•°å­—å…¸
        params = {
            "start": current,
            "end": next_val
        }
        # å¡«å……æ¨¡æ¿
        yield base_template.format(**params)
        current = next_val

# ä½¿ç”¨ç¤ºä¾‹
template = """
SELECT ?film ?filmLabel WHERE {{
  ?film wdt:P31 wd:Q11424 ; wdt:P577 ?date .
  FILTER(?date >= "{start}-01-01"^^xsd:dateTime && ?date < "{end}-01-01"^^xsd:dateTime)
  SERVICE wikibase:label {{ bd:serviceParam wikibase:language "zh,en". }}
}}
"""
for q in query_generator(template, 1900, 2020, 10):
    print(q) # æ‰“å°åˆ‡åˆ†åçš„æŸ¥è¯¢ï¼Œéšåå¯é€å…¥ Fetcher
```
</details>

**ç»ƒä¹  6.4ï¼šå®¡è®¡æ—¥å¿— (Audit Log)**
ä¿®æ”¹ä½ çš„ Fetcher ç±»ã€‚æ¯æ¬¡å‘ç”Ÿç½‘ç»œè¯·æ±‚ï¼ˆä¸æ˜¯ Cache Hitï¼‰æ—¶ï¼Œå‘ä¸€ä¸ªåä¸º `audit.log` çš„æ–‡ä»¶ä¸­å†™å…¥ä¸€è¡Œæ—¥å¿—ã€‚
æ ¼å¼ï¼š`[æ—¶é—´] [çŠ¶æ€ç ] [è€—æ—¶ms] [æŸ¥è¯¢å“ˆå¸Œ] [è¿”å›è®°å½•æ•°]`
è¿™å¯¹äºç›‘æ§ä½ çš„æ•°æ®ç®¡é“å¥åº·çŠ¶å†µéå¸¸é‡è¦ã€‚

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆæ€è·¯</summary>

åœ¨ `_make_request` æ–¹æ³•å†…éƒ¨è®°å½•å¼€å§‹æ—¶é—´ `start = time.time()`ï¼Œè¯·æ±‚ç»“æŸåè®°å½• `end = time.time()`ã€‚
ä½¿ç”¨ Python çš„ `logging` æ¨¡å—æˆ–ç®€å•çš„æ–‡ä»¶è¿½åŠ å†™å…¥ã€‚
```python
duration = (time.time() - start) * 1000
record_count = len(data.get('results', {}).get('bindings', []))
log_line = f"[{time.ctime()}] [{response.status_code}] [{duration:.0f}ms] [{hash}] [{record_count}]\n"
with open("audit.log", "a") as f:
    f.write(log_line)
```
</details>

---

## 7. å¸¸è§é™·é˜±ä¸é”™è¯¯ (Gotchas)

### ğŸ”´ é™·é˜± 1ï¼š`wdt:` vs `p:` çš„æ··æ·†å¯¼è‡´æ•°æ®è†¨èƒ€
å½“ä½ ä¸éœ€è¦é™å®šç¬¦ï¼ˆQualifierï¼‰æˆ–å¼•ç”¨ï¼ˆReferenceï¼‰æ—¶ï¼Œ**åƒä¸‡ä¸è¦**æŸ¥è¯¢ `p:Pxxx`ã€‚
- `wdt:Pxxx`ï¼šç›´æ¥æŒ‡å‘å€¼ï¼ˆTruthy valueï¼‰ï¼Œé€šå¸¸æ¯ä¸ªå±æ€§åªæœ‰ 1-2 ä¸ªå€¼ã€‚
- `p:Pxxx`ï¼šæŒ‡å‘å£°æ˜èŠ‚ç‚¹ï¼ˆStatement nodeï¼‰ã€‚å¦‚æœä½ æŸ¥äº†è¿™ä¸ªèŠ‚ç‚¹ï¼ŒSPARQL ç»“æœé›†ä¼šå‘ç”Ÿç¬›å¡å°”ç§¯çˆ†ç‚¸ã€‚
**Rule**: é™¤éä½ è¦é€ åŒ…å«â€œæ—¶é—´/åœ°ç‚¹/æ¥æºâ€ç­‰ç»†èŠ‚çš„å¤æ‚å¯¹è¯ï¼Œå¦åˆ™åªç”¨ `wdt:`ã€‚

### ğŸ”´ é™·é˜± 2ï¼šLabel Service çš„éšå½¢è¶…æ—¶
`SERVICE wikibase:label { ... }` æ˜¯ä¸ªé»‘ç›’ï¼Œæœ‰æ—¶å€™ä¼šææ…¢ã€‚
**è°ƒè¯•æŠ€å·§**ï¼šå¦‚æœæŸ¥è¯¢è¶…æ—¶ï¼Œå°è¯•å»æ‰ Label Serviceï¼ŒåªæŸ¥ QIDã€‚å¦‚æœé€Ÿåº¦å˜å¿«ï¼Œè¯´æ˜ç“¶é¢ˆåœ¨ Label æœåŠ¡ã€‚æ­¤æ—¶å¯ä»¥åœ¨ Python ç«¯åç»­æ‰¹é‡æŸ¥è¯¢ Labelï¼Œè€Œä¸æ˜¯åœ¨å¤æ‚ SPARQL ä¸­åš Joinã€‚

### ğŸ”´ é™·é˜± 3ï¼šPython å­—å…¸æ— åº (ä½†åœ¨ 3.7+ å·²æ”¹å–„)
è™½ç„¶ Python 3.7+ å­—å…¸ä¿æŒæ’å…¥é¡ºåºï¼Œä½† JSON æ ‡å‡†æœ¬èº«æ˜¯æ— åºçš„ã€‚
ä¸è¦ä¾èµ– `keys()` çš„é¡ºåºæ¥å¯¹é½ CSV åˆ—å¤´ï¼Œå§‹ç»ˆæ˜¾å¼æŒ‡å®šåˆ—ååˆ—è¡¨ã€‚

### ğŸ”´ é™·é˜± 4ï¼šå¿½ç•¥æ•°æ®ç±»å‹çš„è½¬æ¢
SPARQL è¿”å›çš„æ—¶é—´é€šå¸¸æ˜¯ `2023-01-01T00:00:00Z` æ ¼å¼çš„å­—ç¬¦ä¸²ã€‚
åœ¨ç”Ÿæˆå¯¹è¯æ—¶ï¼Œç›´æ¥æŠŠè¿™ä¸ªå­—ç¬¦ä¸²å¡«è¿›æ¨¡æ¿ä¼šå¾ˆæ€ªï¼ˆâ€œä»–åœ¨ 1990-01-01T00:00:00Z å‡ºç”Ÿâ€ï¼‰ã€‚
ä½ éœ€è¦åœ¨**è§„èŒƒåŒ–é˜¶æ®µï¼ˆNormalizerï¼‰**ç¼–å†™å‡½æ•°ï¼Œå°†å…¶è½¬æ¢ä¸ºâ€œ1990å¹´1æœˆ1æ—¥â€æˆ–â€œ1990å¹´â€ã€‚

---

## ä¸‹ä¸€ç« é¢„å‘Š

ç°åœ¨ä½ çš„ç¡¬ç›˜é‡Œå¯èƒ½å·²ç»èººç€ 100 ä¸ª `.jsonl` æ–‡ä»¶ï¼ŒåŒ…å« 50,000 ä¸ªå®ä½“çš„åŸå§‹æ•°æ®ã€‚ä½†å®ƒä»¬è¿˜æ˜¯è¿™ç§æ ¼å¼ï¼š
`{"entity": "Q42", "birth_date": "1952-03-11"}`ã€‚

å¦‚ä½•æŠŠå®ƒå˜æˆï¼šâ€œ*é“æ ¼æ‹‰æ–¯Â·äºšå½“æ–¯å‡ºç”Ÿäº1952å¹´ï¼Œä»–æ˜¯ã€Šé“¶æ²³ç³»æ¼«æ¸¸æŒ‡å—ã€‹çš„ä½œè€…ã€‚*â€ï¼Ÿ
ç”šè‡³å˜æˆå¤šè½®å¯¹è¯ï¼šâ€œ*Q: é“æ ¼æ‹‰æ–¯æ˜¯å“ªå›½äººï¼Ÿ A: è‹±å›½ã€‚*â€ï¼Ÿ

ä¸‹ä¸€ç«  **[Chapter 7ï¼šä¸­æ–‡è‡ªç„¶è¯­è¨€ç”Ÿæˆ](chapter7.md)**ï¼Œæˆ‘ä»¬å°†æ„å»ºæ ¸å¿ƒçš„**æ¨¡æ¿å¼•æ“**ä¸**è‡ªç„¶è¯­è¨€æ¶¦è‰²å™¨**ã€‚
