<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>Chapter 8：质量控制与评估体系：构建数据流水线的“质检局”</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">面向造对话数据的 Wikidata 使用教程（用于生成多样化主题）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 1：Wikidata 与对话数据：为什么它适合做“多样化主题”</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 2：Wikidata 数据模型详解（Q/P/声明/限定符/引用）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 3：WDQS 入门：用 SPARQL 把知识“查出来”</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 4：主题生成：从知识图谱采样“多样化主题池”</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 5：把事实变成对话：多轮结构与标注方案</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 6：自动化抓取与缓存：从 WDQS 到本地数据管道</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 7：中文自然语言生成：从三元组到口语化表达</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 8：质量控制与评估体系：构建数据流水线的“质检局”</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 9：多语言与中文缺失处理</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 10：许可与合规：Wikidata CC0 与对话数据发布注意事项</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 11：工程化实践：从脚本到生产级流水线</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 12：查询模板库与速查表 (Appendices)</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="chapter-8">Chapter 8：质量控制与评估体系：构建数据流水线的“质检局”</h1>
<blockquote>
<p><strong>“数据生成的门槛很低，但高质量数据的门槛极高。”</strong></p>
</blockquote>
<p>在前面的章节中，你已经掌握了如何“生产”数据。现在的挑战是：当你的一键脚本运行了一整晚，生成了 50 万条对话数据后，你如何向你的团队或用户证明这批数据是可用的？</p>
<p>如果数据中充斥着“奥巴马是现任总统”（时效性错误）、90% 都在谈论“复仇者联盟”（覆盖率失衡）或者每句话都像机器人（语言僵硬），那么这批数据对于训练模型不仅无益，反而有害。</p>
<p>本章将教你搭建一套完整的 <strong>QA（Quality Assurance）Pipeline</strong>，涵盖从宏观分布到微观事实的各个层面。</p>
<hr />
<h2 id="1">1. 质量评估流水线概览</h2>
<p>我们建议将质量控制分为三个阶段（Stages）：</p>
<ol>
<li><strong>预计算阶段 (Pre-Computation Analysis)</strong>：在生成对话文本之前，先对采样的<strong>知识图谱子图（KG Subgraph）</strong>进行体检。</li>
<li><strong>后处理阶段 (Post-Generation Audit)</strong>：对生成的自然语言文本进行自动化指标计算。</li>
<li><strong>人工/模型抽检 (Human/LLM-in-the-loop)</strong>：利用少量样本进行深度语义评估。</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="nf">graph</span><span class="w"> </span><span class="n">TD</span>
<span class="w">    </span><span class="n">A</span><span class="p">[</span><span class="n">Wikidata</span><span class="w"> </span><span class="n">Raw</span><span class="w"> </span><span class="n">Dump</span><span class="o">/</span><span class="n">Query</span><span class="p">]</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">B</span><span class="p">(</span><span class="err">预计算</span><span class="o">:</span><span class="w"> </span><span class="err">分布分析</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="err">脏数据清洗</span><span class="p">)</span>
<span class="w">    </span><span class="n">B</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="err">数据生成器</span><span class="p">]</span>
<span class="w">    </span><span class="n">C</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">D</span><span class="p">[</span><span class="err">生成的</span><span class="w"> </span><span class="n">JSONL</span><span class="w"> </span><span class="err">数据</span><span class="p">]</span>
<span class="w">    </span><span class="n">D</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">E</span><span class="p">{</span><span class="err">自动化审计器</span><span class="p">}</span>
<span class="w">    </span><span class="n">E</span><span class="w"> </span><span class="o">--</span><span class="w"> </span><span class="err">包含</span><span class="o">:</span><span class="w"> </span><span class="err">重复率</span><span class="o">/</span><span class="err">正则检查</span><span class="o">/</span><span class="err">事实验证</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">F</span><span class="p">[</span><span class="err">合格数据池</span><span class="p">]</span>
<span class="w">    </span><span class="n">E</span><span class="w"> </span><span class="o">--</span><span class="w"> </span><span class="err">包含</span><span class="o">:</span><span class="w"> </span><span class="err">敏感词</span><span class="o">/</span><span class="err">逻辑错误</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">G</span><span class="p">[</span><span class="err">垃圾桶</span><span class="o">/</span><span class="err">重试队列</span><span class="p">]</span>
<span class="w">    </span><span class="n">F</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">H</span><span class="p">[</span><span class="n">LLM</span><span class="o">-</span><span class="kr">as</span><span class="o">-</span><span class="n">a</span><span class="o">-</span><span class="n">Judge</span><span class="w"> </span><span class="err">抽检</span><span class="p">]</span>
<span class="w">    </span><span class="n">H</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">I</span><span class="p">[</span><span class="err">最终交付数据集</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="kt">Data</span><span class="w"> </span><span class="n">Card</span><span class="p">]</span>
</code></pre></div>

<hr />
<h2 id="2-coverage-diversity">2. 维度一：宏观覆盖率与多样性 (Coverage &amp; Diversity)</h2>
<p>多样性不仅仅是“不一样”，而是“符合预期的分布”。</p>
<h3 id="21-distribution-skewness">2.1 分布偏斜度 (Distribution Skewness)</h3>
<p>不要只看总数，要看<strong>基尼系数</strong>或<strong>头部占比</strong>。</p>
<p><strong>关键指标：</strong></p>
<ul>
<li><strong>Top-K 占比 (Top-K Ratio)</strong>：出现频率最高的 10 个实体/关系占总数据的比例。</li>
<li><em>目标</em>：Top-10 &lt; 5%（除非是专门针对某热门领域的微调数据）。</li>
<li><strong>领域熵 (Entropy of Domains)</strong>：</li>
<li>将数据映射到大类（Q5人物, Q515城市, Q11424电影...）。计算类别的熵值。熵越高，类别分布越均匀。</li>
</ul>
<h3 id="22-blind-spot-detection">2.2 盲区检测 (Blind Spot Detection)</h3>
<p>Wikidata 存在严重的“西方中心主义”和“近代中心主义”。你需要显式地定义<strong>Bucket（桶）</strong>来监控采样：</p>
<p>| Bucket 维度 | 监控逻辑 (Rule-of-Thumb) | 常见失衡现象 | 修正策略 |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Bucket 维度</th>
<th style="text-align: left;">监控逻辑 (Rule-of-Thumb)</th>
<th style="text-align: left;">常见失衡现象</th>
<th style="text-align: left;">修正策略</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>地域 (Geo)</strong></td>
<td style="text-align: left;">统计 <code>P17</code> (国家) 的所属大洲。</td>
<td style="text-align: left;">欧美占 80%，非洲/南美 &lt; 1%。</td>
<td style="text-align: left;">强制采样：对非欧美地区的 QID 进行加权采样（Up-sampling）。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>时间 (Time)</strong></td>
<td style="text-align: left;">统计 <code>P580/P585</code> 的年代。</td>
<td style="text-align: left;">21世纪占 90%，古代史缺失。</td>
<td style="text-align: left;">分层采样：设立 <code>Antiquity</code>, <code>Middle Ages</code>, <code>Modern</code> 时间桶。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>流行度 (Pop)</strong></td>
<td style="text-align: left;">统计 <code>sitelinks</code> 数量。</td>
<td style="text-align: left;">全是维基百科有词条的名人。</td>
<td style="text-align: left;">引入 <code>sitelinks=0</code> 但有丰富声明（statements &gt; 10）的长尾实体。</td>
</tr>
</tbody>
</table>
<h3 id="23-predicate-diversity">2.3 属性多样性 (Predicate Diversity)</h3>
<p>对话不应只聊 <code>P569</code> (出生日期) 和 <code>P19</code> (出生地)。</p>
<ul>
<li><strong>指标</strong>：<strong>Unique Predicates per 1k Dialogues</strong>。</li>
<li><strong>动作</strong>：检查直方图。如果 <code>P17</code> (国家) 出现了 10000 次，而 <code>P166</code> (获奖) 只出现 5 次，你需要调整你的模板选择概率。</li>
</ul>
<hr />
<h2 id="3-micro-level-repetition">3. 维度二：微观重复率 (Micro-level Repetition)</h2>
<p>重复是合成数据的大敌，会导致模型训练过拟合（Overfitting）。</p>
<h3 id="31-n-gram-repetition">3.1 文本级重复 (N-gram Repetition)</h3>
<p>使用 NLP 经典指标来衡量生成的“语言丰富度”：</p>
<ul>
<li>
<p><strong>Distinct-N (D-1, D-2)</strong>：
  $$ \text{Distinct-N} = \frac{\text{Count(Unique N-grams)}}{\text{Count(Total N-grams)}} $$</p>
</li>
<li>
<p><em>解读</em>：D-2 低于 0.4 通常意味着严重的模板重复。</p>
</li>
<li><strong>Self-BLEU</strong>：
  从数据集中随机抽取一条作为 Hypothesis，其余作为 References 计算 BLEU。分数越低越好（说明每条句子都长得不一样）。</li>
</ul>
<h3 id="32-semantic-collision">3.2 语义级重复 (Semantic Collision)</h3>
<p>有些句子虽然字不一样，但意思是完全重复的。</p>
<ul>
<li><strong>Jaccard 相似度去重</strong>：</li>
<li>句子 A：“乔布斯是苹果的创办人。”</li>
<li>句子 B：“苹果公司是由乔布斯创立的。”</li>
<li><em>策略</em>：对于同一对 (Entity, Attribute)，如果生成了多条数据，计算它们的 Jaccard Similarity。如果 &gt; 0.8，丢弃其中一条。</li>
</ul>
<h3 id="33">3.3 模板复用率监控</h3>
<p>如果你有 100 个模板，但脚本因为某些逻辑 bug 只用到了前 5 个，数据会极其单调。</p>
<ul>
<li><strong>审计方法</strong>：在生成日志中记录 <code>template_id</code>。绘制模板使用热力图，确保长尾模板也被调用。</li>
</ul>
<hr />
<h2 id="4-factual-consistency">4. 维度三：事实一致性 (Factual Consistency) —— 核心难点</h2>
<p>这是 Wikidata 数据的生命线。我们需要构建一个 <strong>Fact Validator (事实校验器)</strong>。</p>
<h3 id="41-temporal-validity">4.1 深度时效性校验 (Temporal Validity)</h3>
<p>最容易出错的是“前任”与“现任”的混淆。</p>
<p><strong>校验逻辑伪代码：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">check_temporal_validity</span><span class="p">(</span><span class="n">statement</span><span class="p">,</span> <span class="n">current_year</span><span class="o">=</span><span class="mi">2024</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    判断一个事实在当下是否依然为真</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">statement</span><span class="o">.</span><span class="n">get_qualifier</span><span class="p">(</span><span class="s1">&#39;P580&#39;</span><span class="p">)</span> <span class="c1"># start time</span>
    <span class="n">end_time</span> <span class="o">=</span> <span class="n">statement</span><span class="o">.</span><span class="n">get_qualifier</span><span class="p">(</span><span class="s1">&#39;P582&#39;</span><span class="p">)</span>   <span class="c1"># end time</span>

    <span class="c1"># 情况 1: 已经结束的事实</span>
    <span class="k">if</span> <span class="n">end_time</span> <span class="ow">and</span> <span class="n">parse_year</span><span class="p">(</span><span class="n">end_time</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">current_year</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;PAST&quot;</span> <span class="c1"># 应该是 &quot;曾任&quot; / &quot;前&quot;</span>

    <span class="c1"># 情况 2: 未来才开始的事实 (例如预定的奥运会)</span>
    <span class="k">if</span> <span class="n">start_time</span> <span class="ow">and</span> <span class="n">parse_year</span><span class="p">(</span><span class="n">start_time</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">current_year</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;FUTURE&quot;</span> <span class="c1"># 应该是 &quot;将担任&quot; / &quot;计划于&quot;</span>

    <span class="c1"># 情况 3: 正在进行</span>
    <span class="k">return</span> <span class="s2">&quot;PRESENT&quot;</span> <span class="c1"># 应该是 &quot;是&quot; / &quot;现任&quot;</span>
</code></pre></div>

<p><strong>Rule-of-Thumb</strong>:</p>
<ul>
<li>生成文本中如果包含“<strong>是</strong>”、“<strong>现任</strong>”、“<strong>正在</strong>”，但三元组有 <code>P582</code> (end time)，标记为 <strong>Error</strong>。</li>
<li>生成文本中如果包含“<strong>曾</strong>”、“<strong>前</strong>”，但三元组没有 <code>P582</code> 且有 <code>P580</code>，标记为 <strong>Warning</strong> (可能是现任，也可能只是数据缺失)。</li>
</ul>
<h3 id="42-uniqueness-violation">4.2 唯一性冲突 (Uniqueness Violation)</h3>
<p>某些属性在常识中是“单值”的，但在 Wikidata 中可能有多个值（历史遗留或争议）。</p>
<ul>
<li><strong>例子</strong>：<code>P1376</code> (capital of)。中国历史上有多个首都。</li>
<li><strong>校验</strong>：对于单值语义的属性（如出生地、生父、死亡日期），如果 API 返回了列表长度 &gt; 1，<strong>必须</strong>检查限定符，否则极易生成“某人死于1990年和1991年”的胡话。</li>
</ul>
<h3 id="43-value-unit-normalization">4.3 数值与单位归一化 (Value &amp; Unit Normalization)</h3>
<p>Wikidata 的数值往往带有单位 QID（如 Q4917 米, Q21857 英尺）。</p>
<ul>
<li><strong>陷阱</strong>：建筑高度。有些条目是米，有些是英尺。</li>
<li><strong>审计</strong>：建立一个 <code>Unit Converter</code>。</li>
<li><em>错误</em>：Eiffel Tower height is 1063 (Raw value, actually feet).</li>
<li><em>修正</em>：检测到单位是 feet -&gt; 转换为 324 meters -&gt; 生成文本 "324米"。</li>
<li><em>自动检查</em>：提取生成文本中的数字，与 Wikidata raw value 进行量纲比对。</li>
</ul>
<hr />
<h2 id="5-naturalness-hallucination">5. 维度四：自然度与幻觉 (Naturalness &amp; Hallucination)</h2>
<h3 id="51-wikipedia-style">5.1 拒绝“百科腔” (Wikipedia Style)</h3>
<p>对话数据需要口语化。</p>
<ul>
<li><strong>检测特征</strong>：</li>
<li>过长的定语从句。</li>
<li>括号注释过多：如 "北京（中国的首都）"。</li>
<li>书面连接词：“然而”、“故此”、“综上所述”。</li>
<li><strong>评分</strong>：使用 Perplexity (PPL) 或简单的规则过滤器，剔除过于书面化的句子。</li>
</ul>
<h3 id="52-hallucination-check">5.2 幻觉检测 (Hallucination Check)</h3>
<p>当模板中的槽位（Slot）未被正确填充，或者填充了错误的实体标签时。</p>
<ul>
<li><strong>标签回退导致的幻觉</strong>：</li>
<li>英文标签：<code>Q123 -&gt; "Big Bank (defunct)"</code></li>
<li>粗暴翻译/回退：生成文本“<strong>大银行（倒闭）</strong>位于纽约。”</li>
<li><em>问题</em>：括号里的内容不应直接读出来。</li>
<li><em>修正</em>：预处理清洗 Label，去除括号、消歧义后缀。</li>
</ul>
<hr />
<h2 id="6-llm-as-a-judge">6. 进阶：LLM-as-a-Judge (用大模型评分)</h2>
<p>对于复杂的逻辑和流畅度，规则很难判断。当前业界的做法是采样 1% 的数据，送给 GPT-4 或 Qwen-Max 进行打分。</p>
<h3 id="61-prompt-template">6.1 提示词模板 (Prompt Template)</h3>
<div class="codehilite"><pre><span></span><code>你是一个严格的数据质量审计员。请评估以下基于知识库生成的对话数据。

<span class="gs">**输入数据：**</span>

<span class="k">-</span><span class="w"> </span>知识三元组：{Subject: 埃隆·马斯克, Predicate: CEO of, Object: Tesla, Start: 2008}
<span class="k">-</span><span class="w"> </span>生成对话：
  A: &quot;你知道谁是特斯拉的老板吗？&quot;
  B: &quot;当然，埃隆·马斯克从2008年开始就一直担任特斯拉的CEO。&quot;

<span class="gs">**评估维度（1-5分）：**</span>

<span class="k">1.</span> <span class="gs">**事实一致性**</span>：对话是否准确反映了三元组信息？有没有编造？
<span class="k">2.</span> <span class="gs">**自然度**</span>：对话是否像人类的日常闲聊？
<span class="k">3.</span> <span class="gs">**逻辑性**</span>：问答逻辑是否连贯？

<span class="gs">**输出格式：**</span>
JSON: {&quot;consistency&quot;: 5, &quot;naturalness&quot;: 4, &quot;logic&quot;: 5, &quot;reason&quot;: &quot;...&quot;}
</code></pre></div>

<h3 id="62">6.2 审计报告</h3>
<p>根据 LLM 的打分，生成 <strong>Pass Rate</strong>。如果自然度平均分 &lt; 3.5，说明模板库需要重写。</p>
<hr />
<h2 id="7">7. 本章小结</h2>
<p>质量控制不是生成后的“补救”，而是贯穿全流程的“工程”。</p>
<ol>
<li><strong>Macro（宏观）</strong>：用 Bucket 和 Gini 系数监控覆盖率，拒绝数据偏见。</li>
<li><strong>Micro（微观）</strong>：用 Distinct-N 和 Jaccard 监控重复率，拒绝复读机。</li>
<li><strong>Truth（真相）</strong>：用时间逻辑和单位换算器构建 Validator，拒绝事实错误。</li>
<li><strong>Audit（审计）</strong>：引入 LLM-as-a-Judge 进行最终把关。</li>
</ol>
<hr />
<h2 id="8">8. 练习题</h2>
<h3 id="_1">基础题</h3>
<h4 id="1_1">练习 1：编写一个简单的“时间冲突”检测器</h4>
<p><strong>场景</strong>：你生成了一句话“迈克尔·杰克逊现在住在洛杉矶。”
<strong>已知事实</strong>：<code>Michael Jackson (Q2808)</code> -&gt; <code>date of death (P570)</code> -&gt; <code>2009-06-25</code>.
<strong>任务</strong>：写一段 Python 伪代码，输入是 (Entity_Dict, Generated_Text)，如果检测到死者使用了“现在/正在”等存活状态词，返回 False。</p>
<details>
<summary>点击展开答案</summary>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">check_alive_status</span><span class="p">(</span><span class="n">entity_data</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
    <span class="c1"># 1. 检查实体是否有死亡日期</span>
    <span class="n">death_date</span> <span class="o">=</span> <span class="n">entity_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;claims&#39;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;P570&#39;</span><span class="p">)</span>
    <span class="n">is_dead</span> <span class="o">=</span> <span class="n">death_date</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="c1"># 2. 定义“存活状态”的敏感词</span>
    <span class="n">alive_keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;现在&quot;</span><span class="p">,</span> <span class="s2">&quot;正在&quot;</span><span class="p">,</span> <span class="s2">&quot;现任&quot;</span><span class="p">,</span> <span class="s2">&quot;目前&quot;</span><span class="p">,</span> <span class="s2">&quot;living in&quot;</span><span class="p">,</span> <span class="s2">&quot;is a&quot;</span><span class="p">]</span>

    <span class="c1"># 3. 冲突检测</span>
    <span class="k">if</span> <span class="n">is_dead</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">alive_keywords</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Error: Entity is dead (died </span><span class="si">{</span><span class="n">death_date</span><span class="si">}</span><span class="s2">), but text implies alive using &#39;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2">&#39;.&quot;</span>

    <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;OK&quot;</span>
</code></pre></div>

<p><strong>提示</strong>：实际工程中，还需要考虑“过去时”的表达（如“他生前住在...”）是允许的，所以需要依赖句法分析或更严格的模板匹配。</p>
</details>
<h4 id="2-distinct-2">练习 2：计算 Distinct-2 指标</h4>
<p>给定以下三句话，计算 Distinct-2 (Bigram) 的比率。</p>
<ol>
<li>"北京是中国的首都"</li>
<li>"东京是日本的首都"</li>
<li>"巴黎是法国的首都"
<em>(假设分词后为：北京/是/中国/的/首都)</em></li>
</ol>
<details>
<summary>点击展开答案</summary>
<p><strong>分词序列</strong>：</p>
<ol>
<li><code>[北京, 是, 中国, 的, 首都]</code> -&gt; Bigrams: <code>(北京,是), (是,中国), (中国,的), (的,首都)</code></li>
<li><code>[东京, 是, 日本, 的, 首都]</code> -&gt; Bigrams: <code>(东京,是), (是,日本), (日本,的), (的,首都)</code></li>
<li><code>[巴黎, 是, 法国, 的, 首都]</code> -&gt; Bigrams: <code>(巴黎,是), (是,法国), (法国,的), (的,首都)</code></li>
</ol>
<p><strong>统计</strong>：</p>
<ul>
<li>Total Bigrams = 4 + 4 + 4 = 12</li>
<li>Unique Bigrams:</li>
<li>重复的: <code>(的,首都)</code> 出现3次 (计为1个unique)</li>
<li>其它的: <code>(北京,是)...</code> 等9个各不相同</li>
<li>Unique count = 9 + 1 = 10 ? </li>
<li>实际上：<code>(北京,是), (是,中国), (中国,的), (的,首都), (东京,是), (是,日本), (日本,的), (巴黎,是), (是,法国), (法国,的)</code></li>
<li>其中 <code>(的,首都)</code> 是共用的。</li>
<li>Unique Bigrams Set Size = 10.</li>
</ul>
<p><strong>计算</strong>：
Distinct-2 = 10 / 12 ≈ 0.83</p>
<p><strong>结论</strong>：这个分数看起来很高，但这是因为实体名不同。如果你把实体名都 mask 成 <code>&lt;LOC&gt;</code>, 句子变成 <code>&lt;LOC&gt;是&lt;LOC&gt;的首都</code>，重复率就是 100%。<strong>这也是为什么评估模板多样性时，建议先 Mask 掉实体词再计算。</strong></p>
</details>
<hr />
<h3 id="_2">挑战题</h3>
<h4 id="1_2">挑战 1：设计“多值消歧”策略</h4>
<p><strong>背景</strong>：属性 <code>P161</code> (cast member/演员表) 对于电影《复仇者联盟》有几十个值。
<strong>问题</strong>：如果在对话中列举所有演员，句子会过长且不自然。如果只随机选一个，用户可能会觉得“为什么不说钢铁侠？”。
<strong>任务</strong>：设计一个算法，基于 Wikidata 的数据特征，选择“最重要”的 3 个演员。</p>
<details>
<summary>点击展开提示</summary>
<p><strong>Hint</strong>:
Wikidata 的 <code>statement</code> 列表本身不保证顺序。你需要引入外部辅助数据或内部隐含特征。</p>
<ol>
<li>检查 <code>P161</code> 是否有 Qualifier <code>P39</code> (character role) 或 <code>P453</code> (character role)。这不一定能解决“主角”问题。</li>
<li><strong>利用 Sitelinks</strong>: 演员本身的知名度（Sitelinks 数量）通常与他们在电影中的重要性正相关。</li>
<li><strong>利用 Image</strong>: 有头像图片的演员通常比没有的更重要。</li>
</ol>
</details>
<details>
<summary>点击展开答案</summary>
<p><strong>推荐算法</strong>：</p>
<ol>
<li>获取电影的所有 <code>P161</code> 目标实体（演员 QIDs）。</li>
<li>对每个演员 QID，查询其 <code>wikibase:sitelinks</code> 计数。</li>
<li>按 Sitelinks 降序排列。</li>
<li>取 Top-3。</li>
</ol>
<p><strong>逻辑</strong>：小罗伯特·唐尼（Iron Man）的词条链接数肯定远多于某个龙套演员。这种基于<strong>PageRank 思想</strong>的排序在知识图谱中非常有效。</p>
</details>
<h4 id="2-negative-sampling">挑战 2：构建“反事实”负样本 (Negative Sampling)</h4>
<p>为了训练模型不仅知道“什么是对的”，还要知道“什么是错的”，你需要特意生成一些错误的对话作为负样本（用于训练 Reward Model 或判别器）。
<strong>任务</strong>：基于正确三元组 <code>(奥巴马, 出生于, 檀香山)</code>，设计三种不同类型的“错误生成策略”。</p>
<details>
<summary>点击展开答案</summary>
<p><strong>策略 1：实体替换 (Entity Swap)</strong></p>
<ul>
<li>保持关系不变，替换 Object 为同类型的其他实体。</li>
<li>生成：“奥巴马出生于<strong>纽约</strong>。” (选取一个热门的错误城市)</li>
</ul>
<p><strong>策略 2：关系错误 (Relation Error)</strong></p>
<ul>
<li>保持实体不变，替换 Predicate。</li>
<li>生成：“奥巴马<strong>逝世于</strong>檀香山。” (将 P19 出生地 替换为 P20 死亡地)</li>
</ul>
<p><strong>策略 3：时序错乱 (Temporal Glitch)</strong></p>
<ul>
<li>针对有时间限定符的事实，修改时间。</li>
<li>生成：“奥巴马<strong>在1860年</strong>出生于檀香山。”</li>
</ul>
<p><strong>用途</strong>：这类数据对于训练模型的“幻觉检测”能力极具价值。</p>
</details>
<hr />
<h2 id="9-gotchas">9. 常见陷阱与错误 (Gotchas)</h2>
<p>| 陷阱 | 现象 | 调试/解决方法 |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">陷阱</th>
<th style="text-align: left;">现象</th>
<th style="text-align: left;">调试/解决方法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>"The Unknown"</strong></td>
<td style="text-align: left;">某些值是 "unknown value" (Wikidata 里的特殊节点)，脚本将其当做普通 QID 处理。</td>
<td style="text-align: left;">检查 <code>snaktype</code>。如果不是 <code>value</code> 而是 <code>somevalue</code> 或 <code>novalue</code>，生成的文本应为“具体不详”而不是报错或乱码。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>坐标系的灾难</strong></td>
<td style="text-align: left;"><code>P625</code> (Coordinate) 返回的是 JSON <code>{'latitude': ..., 'longitude': ...}</code>，直接转字符串会很难看。</td>
<td style="text-align: left;">需要专门的 Geo-Template，将坐标转换为“位于北纬X度”或者结合 <code>P17</code> 说“位于某国”。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>多语言混合列表</strong></td>
<td style="text-align: left;">生成列表时："苹果、Banana、Orange"。</td>
<td style="text-align: left;">检查 Label 的 <code>language</code> 字段。如果中文缺失，宁可丢弃该项，也不要中英混杂（除非你的设定允许）。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>递归死循环</strong></td>
<td style="text-align: left;">在追踪 <code>subclass of</code> (P279) 寻找父类时，数据中存在环路 (A is sub of B, B is sub of A)。</td>
<td style="text-align: left;">设置最大递归深度（Max Depth = 5），防止脚本挂死。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>JSONL 格式逃逸</strong></td>
<td style="text-align: left;">生成的文本中包含换行符 <code>\n</code> 或双引号 <code>"</code>，破坏了 JSONL 结构。</td>
<td style="text-align: left;">务必使用 <code>json.dumps()</code> 进行序列化，严禁手动字符串拼接 <code>"{...}"</code>。</td>
</tr>
</tbody>
</table>
<hr />
<p><a href="chapter7.html">&lt; Chapter 7：中文自然语言生成</a> | <a href="chapter9.html">Chapter 9：多语言与中文缺失处理 &gt;</a></p>
            </article>
            
            <nav class="page-nav"><a href="chapter7.html" class="nav-link prev">← Chapter 7：中文自然语言生成：从三元组到口语化表达</a><a href="chapter9.html" class="nav-link next">Chapter 9：多语言与中文缺失处理 →</a></nav>
        </main>
    </div>
</body>
</html>